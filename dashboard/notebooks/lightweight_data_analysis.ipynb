{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df9d5fb1",
   "metadata": {},
   "source": [
    "# üìä Lightweight Data Analysis - Diabetes Prediction\n",
    "### Alternatif Ringan untuk Hive menggunakan PySpark dan Jupyter\n",
    "\n",
    "Notebook ini memberikan alternatif yang lebih ringan dibandingkan Hive untuk:\n",
    "- Query data di HDFS\n",
    "- Analisis data interaktif\n",
    "- Visualisasi sederhana\n",
    "- Export metrics untuk Grafana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785841e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup PySpark dengan konfigurasi ringan\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Konfigurasi Spark yang ringan\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DiabetesAnalysisNotebook\") \\\n",
    "    .config(\"spark.executor.memory\", \"512m\") \\\n",
    "    .config(\"spark.driver.memory\", \"256m\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(\"‚úÖ Spark Session initialized with lightweight configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd3cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data dari HDFS (Bronze layer)\n",
    "try:\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\") \\\n",
    "        .csv(\"hdfs://namenode:9000/data/bronze/diabetes.csv\")\n",
    "    \n",
    "    print(f\"‚úÖ Data loaded successfully: {df.count()} records\")\n",
    "    \n",
    "    # Show schema\n",
    "    print(\"\\nüìã Data Schema:\")\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Show sample data\n",
    "    print(\"\\nüìä Sample Data:\")\n",
    "    df.show(5)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")\n",
    "    # Fallback to local data\n",
    "    print(\"üîÑ Trying to load from local path...\")\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\") \\\n",
    "        .csv(\"/opt/data/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badc5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat temporary view untuk SQL queries (Alternatif Hive Tables)\n",
    "df.createOrReplaceTempView(\"diabetes\")\n",
    "print(\"‚úÖ Temporary view 'diabetes' created\")\n",
    "\n",
    "# Basic statistics menggunakan SQL\n",
    "basic_stats = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_records,\n",
    "        SUM(CASE WHEN Outcome = 1 THEN 1 ELSE 0 END) as diabetic_count,\n",
    "        SUM(CASE WHEN Outcome = 0 THEN 1 ELSE 0 END) as non_diabetic_count,\n",
    "        ROUND(AVG(Glucose), 2) as avg_glucose,\n",
    "        ROUND(AVG(BMI), 2) as avg_bmi,\n",
    "        ROUND(AVG(Age), 2) as avg_age,\n",
    "        ROUND(AVG(BloodPressure), 2) as avg_blood_pressure\n",
    "    FROM diabetes\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüìà Basic Statistics:\")\n",
    "basic_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8da7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query analisis usia (seperti Hive table queries)\n",
    "age_analysis = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN Age < 30 THEN '20-29'\n",
    "            WHEN Age < 40 THEN '30-39'\n",
    "            WHEN Age < 50 THEN '40-49'\n",
    "            WHEN Age < 60 THEN '50-59'\n",
    "            ELSE '60+'\n",
    "        END as age_group,\n",
    "        COUNT(*) as total_count,\n",
    "        SUM(CASE WHEN Outcome = 1 THEN 1 ELSE 0 END) as diabetic_count,\n",
    "        ROUND(AVG(Glucose), 2) as avg_glucose,\n",
    "        ROUND(AVG(BMI), 2) as avg_bmi\n",
    "    FROM diabetes\n",
    "    GROUP BY age_group\n",
    "    ORDER BY age_group\n",
    "\"\"\")\n",
    "\n",
    "print(\"üë• Age Group Analysis:\")\n",
    "age_analysis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dbb16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi sederhana (tanpa beban berat)\n",
    "# Convert ke Pandas untuk plotting ringan\n",
    "age_data = age_analysis.toPandas()\n",
    "\n",
    "# Plot distribusi usia\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(age_data['age_group'], age_data['total_count'], color='lightblue', alpha=0.7)\n",
    "plt.title('Distribution by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(age_data['age_group'], age_data['diabetic_count'], color='orange', alpha=0.7)\n",
    "plt.title('Diabetic Cases by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Diabetic Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Visualizations created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae66bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query lanjutan untuk korelasi (seperti advanced Hive queries)\n",
    "correlation_analysis = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN Glucose < 100 THEN 'Normal (<100)'\n",
    "            WHEN Glucose < 140 THEN 'Pre-diabetic (100-139)'\n",
    "            ELSE 'Diabetic (140+)'\n",
    "        END as glucose_category,\n",
    "        CASE \n",
    "            WHEN BMI < 18.5 THEN 'Underweight'\n",
    "            WHEN BMI < 25 THEN 'Normal'\n",
    "            WHEN BMI < 30 THEN 'Overweight'\n",
    "            ELSE 'Obese'\n",
    "        END as bmi_category,\n",
    "        COUNT(*) as count,\n",
    "        SUM(CASE WHEN Outcome = 1 THEN 1 ELSE 0 END) as diabetic_cases,\n",
    "        ROUND((SUM(CASE WHEN Outcome = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(*)), 2) as diabetes_rate\n",
    "    FROM diabetes\n",
    "    WHERE Glucose > 0 AND BMI > 0\n",
    "    GROUP BY glucose_category, bmi_category\n",
    "    ORDER BY diabetes_rate DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"üîç Glucose-BMI Correlation Analysis:\")\n",
    "correlation_analysis.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a230a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export metrics untuk Grafana (seperti Hive export)\n",
    "def export_metrics_for_grafana():\n",
    "    # Collect data untuk export\n",
    "    basic_stats_dict = basic_stats.collect()[0].asDict()\n",
    "    age_distribution = [row.asDict() for row in age_analysis.collect()]\n",
    "    correlation_data = [row.asDict() for row in correlation_analysis.collect()]\n",
    "    \n",
    "    # Prepare metrics JSON\n",
    "    metrics = {\n",
    "        \"basic_stats\": basic_stats_dict,\n",
    "        \"age_distribution\": age_distribution,\n",
    "        \"correlation_analysis\": correlation_data,\n",
    "        \"daily_metrics\": {\n",
    "            \"records_processed\": basic_stats_dict[\"total_records\"],\n",
    "            \"avg_glucose\": basic_stats_dict[\"avg_glucose\"],\n",
    "            \"avg_bmi\": basic_stats_dict[\"avg_bmi\"],\n",
    "            \"positive_predictions\": basic_stats_dict[\"diabetic_count\"],\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"date\": datetime.now().strftime('%Y-%m-%d')\n",
    "        },\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    # Save to JSON file\n",
    "    output_path = \"/tmp/diabetes_metrics.json\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"‚úÖ Metrics exported to {output_path}\")\n",
    "    print(\"üìä Summary:\")\n",
    "    print(f\"  - Total Records: {basic_stats_dict['total_records']}\")\n",
    "    print(f\"  - Diabetic Cases: {basic_stats_dict['diabetic_count']}\")\n",
    "    print(f\"  - Average Glucose: {basic_stats_dict['avg_glucose']}\")\n",
    "    print(f\"  - Average BMI: {basic_stats_dict['avg_bmi']}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Export metrics\n",
    "exported_metrics = export_metrics_for_grafana()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f70174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom queries (seperti ad-hoc Hive queries)\n",
    "print(\"üîß Custom Query Examples:\")\n",
    "print(\"\\n1. High Risk Patients (Glucose > 140 AND BMI > 30):\")\n",
    "\n",
    "high_risk = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as high_risk_count,\n",
    "        SUM(CASE WHEN Outcome = 1 THEN 1 ELSE 0 END) as confirmed_diabetic,\n",
    "        ROUND(AVG(Age), 2) as avg_age,\n",
    "        ROUND(AVG(Pregnancies), 2) as avg_pregnancies\n",
    "    FROM diabetes\n",
    "    WHERE Glucose > 140 AND BMI > 30\n",
    "\"\"\")\n",
    "\n",
    "high_risk.show()\n",
    "\n",
    "print(\"\\n2. Pregnancy Impact Analysis:\")\n",
    "pregnancy_impact = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN Pregnancies = 0 THEN 'No Pregnancy'\n",
    "            WHEN Pregnancies <= 2 THEN '1-2 Pregnancies'\n",
    "            WHEN Pregnancies <= 5 THEN '3-5 Pregnancies'\n",
    "            ELSE '6+ Pregnancies'\n",
    "        END as pregnancy_group,\n",
    "        COUNT(*) as total,\n",
    "        SUM(CASE WHEN Outcome = 1 THEN 1 ELSE 0 END) as diabetic,\n",
    "        ROUND((SUM(CASE WHEN Outcome = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(*)), 2) as diabetes_rate\n",
    "    FROM diabetes\n",
    "    GROUP BY pregnancy_group\n",
    "    ORDER BY diabetes_rate DESC\n",
    "\"\"\")\n",
    "\n",
    "pregnancy_impact.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc052fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "print(\"üßπ Cleaning up resources...\")\n",
    "spark.stop()\n",
    "print(\"‚úÖ Spark session stopped\")\n",
    "print(\"\\nüìã Summary:\")\n",
    "print(\"  ‚úÖ Data loaded and analyzed successfully\")\n",
    "print(\"  ‚úÖ Metrics exported for Grafana\")\n",
    "print(\"  ‚úÖ Alternative to Hive implemented using PySpark\")\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"  1. Run the export script: ./scripts/query/export_for_grafana.sh\")\n",
    "print(\"  2. Access Grafana: http://localhost:3000\")\n",
    "print(\"  3. Login with: admin / grafana_admin_2025\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
